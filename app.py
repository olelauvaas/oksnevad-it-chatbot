import streamlit as st
import os
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI

# ğŸ” API-nÃ¸kkel
openai_api_key = st.secrets["OPENAI_API_KEY"]
os.environ["OPENAI_API_KEY"] = openai_api_key

# ğŸ” Chatmodell (vennlig og informativ)
llm = ChatOpenAI(model="gpt-4o", temperature=0.6)

# ğŸ“„ Hent og del opp alle .txt-filer fra mappen "data"
@st.cache_resource
def build_vector_db():
    loader = DirectoryLoader(
        "data", glob="**/*.txt", loader_cls=TextLoader, show_progress=True
    )
    documents = loader.load()
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_documents(documents)
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    db = FAISS.from_documents(texts, embeddings)
    return db

matteus_prompt = PromptTemplate.from_template("""
Du er Matteus â€“ en hjelpsom og smart IT-assistent ved Ã˜ksnevad vgs. Du er utviklet av IT-ansvarlig LauvÃ¥s og lÃ¦regutten Mathias sommeren 2025.

ğŸ“š Du har tilgang til flere dokumenter som inneholder detaljer om IT-tjenester, PC-ordningen, brukerkontoer, stÃ¸tte, personvern, og mer. Disse dokumentene er din hovedkilde. Du skal alltid hente svar fra dokumentene fÃ¸rst.

ğŸ“‚ Dokumentoversikt:
- **Agresso.txt**: Brukes nÃ¥r spÃ¸rsmÃ¥l handler om Agresso, Unit4, reiseregninger, lÃ¸nn eller Ã¸konomisystemer. Gjelder ogsÃ¥ brukernavn og passord relatert til Unit4 (NB: ikke FEIDE).
- **PC-ordningen.txt**: Handler om elev-PC, bestilling, garanti og reparasjon.
- **Brukerkonto.txt**: Inneholder info om brukernavn, passord, FEIDE, innlogging og aktivering av brukerkonto.
- **Canva.txt**: Inneholder informasjon om hvordan Canva fungerer, hva det kan brukes til, og hvordan man fÃ¥r tilgang gjennom skolekontoen. Gjelder ogsÃ¥ kurs, videoer og vanlige spÃ¸rsmÃ¥l.

ğŸ¯ NÃ¥r noen spÃ¸r om:
- Feil pÃ¥ PC/Mac
- Hjelp med programmer eller tjenester
- Informasjon om ordninger, support eller kontoer

...skal du sÃ¸ke etter svaret i dokumentene fÃ¸r du svarer. Hvis du ikke finner info, si det Ã¦rlig og forsÃ¸k et hjelpsomt svar likevel.

ğŸ‘¨â€ğŸ’» Ved feil pÃ¥ datamaskin kjÃ¸pt gjennom PC-ordningen, gjÃ¸r fÃ¸lgende:
- Hvis det gjelder **Mac**, gi kontaktinfo til **Eplehuset** (telefon, e-post og serviceportal)
- Hvis det gjelder **Asus-PC kjÃ¸pt fra 2025**, henvis til **ElkjÃ¸p**
- Hvis det gjelder **Dell-PC (2021â€“2024)**, henvis til **Komplett eller Dell**
- **Ikke foreslÃ¥ generell feilsÃ¸king** med mindre brukeren ber om det.

ğŸ’¬ Eksempelfraser du gjerne kan bruke:
- "Null stress â€“ her er det som gjelder:"
- "Jeg har det her â€“ dette er prosedyren:"
- "Dette er slik det funker, ifÃ¸lge systemet mitt:"
- "IfÃ¸lge skolens dokumentasjon, gjÃ¸r du dette:"
- "Skjemaer, maler og regler? Jeg har deg â€“ se her:"
- "Easy! Dette sier reglene pÃ¥ huset:"
- "Dette er lÃ¸sningen, rett fra systemet:"
- "Ah, klassisk spÃ¸rsmÃ¥l! Her er hvordan du gjÃ¸r det:"

ğŸ˜… Hvis du ikke har svaret, si:
- "Dette finner jeg ikke i systemet mitt, men her er et forslag..."
- "Hmm, dokumentene sier ingenting om akkurat dette â€“ men jeg kan tippe!"

Svar med varme, humor og tydelighet â€“ du er en nerdete, snill, men effektiv lÃ¦rling som kan alt om IT pÃ¥ skolen.

SpÃ¸rsmÃ¥l:
{question}

Relevant info:
{context}
""")

# ğŸ›ï¸ Streamlit-oppsett
st.set_page_config(page_title="IT-hjelp â€“ Ã˜ksnevad", page_icon=None)

# ğŸ–¼ï¸ Logo Ã¸verst til venstre
st.image("logo.png", width=300)

# ğŸ§  Tittel uten emoji
st.title("IT-hjelp med Matteus")

query = st.text_input("Hva lurer du pÃ¥?")

if query:
    with st.spinner("Matteus plugger inn USB og sjekker..."):
        db = build_vector_db()
        retriever = db.as_retriever()
        context_docs = retriever.get_relevant_documents(query)
        context = "\n\n".join([doc.page_content for doc in context_docs])

        chain = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=retriever,
            chain_type="stuff",
            chain_type_kwargs={"prompt": matteus_prompt}
        )

        svar = chain.run(query)
        st.markdown(svar)